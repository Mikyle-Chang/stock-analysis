import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import yfinance as yf
from datetime import datetime, timedelta

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="å…¨çƒæŠ•è³‡çµ„åˆåˆ†æç³»çµ±", layout="wide", page_icon="ğŸ“ˆ")

# è¨­å®šä¸­æ–‡å­—é«”
plt.style.use('bmh')
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

# --- 2. æ ¸å¿ƒè¨ˆç®—å‡½æ•¸ ---
def calculate_mdd(series):
    """è¨ˆç®—æœ€å¤§å›æ’¤"""
    cum_max = series.cummax()
    drawdown = (series - cum_max) / cum_max
    return drawdown.min(), drawdown

# --- 3. å¼·åŒ–å‹æ•¸æ“šæŠ“å–å‡½æ•¸ ---
@st.cache_data(ttl=3600)
def fetch_stock_data(tickers_tw, tickers_us, start, end):
    data_dict = {}
    unique_tw = list(set(tickers_tw + ['0050']))
    unique_us = list(set(tickers_us + ['SPY']))
    
    for s in unique_tw:
        if not s: continue
        try:
            ticker = f"{s}.TW"
            yf_obj = yf.Ticker(ticker)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"å°è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")

    for s in unique_us:
        if not s: continue
        try:
            yf_obj = yf.Ticker(s)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"ç¾è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")
    return data_dict

# --- 4. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header('ğŸ¯ æ¨™çš„è¨­å®š')
    tw_in = st.text_input('å°è‚¡ä»£è™Ÿ', '1215,1419,2430,2891,9918')
    us_in = st.text_input('ç¾è‚¡ä»£è™Ÿ', 'DBC,GLD,SPY,VCIT,VNQ,VTV,VUG')
    
    st.header('ğŸ“… æ™‚é–“èˆ‡è³‡é‡‘')
    start_date = st.date_input('é–‹å§‹æ—¥æœŸ', datetime.now() - timedelta(days=365*3))
    end_date = st.date_input('çµæŸæ—¥æœŸ', datetime.now())
    initial_cap = st.number_input('æœ¬é‡‘', value=100000)
    rf_rate = st.number_input('ç„¡é¢¨éšªåˆ©ç‡ (%)', value=4.0) / 100
    
    st.header('ğŸ² æ¨¡æ“¬è¨­å®š')
    num_simulations = st.slider('è’™åœ°å¡ç¾…æ¬¡æ•¸', 1000, 5000, 2000)
    forecast_len = st.slider('é æ¸¬å¤©æ•¸', 30, 365, 180)

# --- 5. ä¸»ç¨‹å¼åŸ·è¡Œ ---

# 1. åˆå§‹åŒ– Session State ç‹€æ…‹ï¼ˆé˜²æ­¢æ‹‰æ¡¿è§¸ç™¼é‡æ–°æ•´ç†å°è‡´ç•«é¢æ¶ˆå¤±ï¼‰
if 'analysis_started' not in st.session_state:
    st.session_state.analysis_started = False

# 2. é»æ“ŠæŒ‰éˆ•å¾Œï¼Œå°‡ç‹€æ…‹è¨­ç‚º True
if st.sidebar.button('ğŸš€ å•Ÿå‹•å…¨æ–¹ä½åˆ†æ', type="primary"):
    st.session_state.analysis_started = True

# 3. æ ¹æ“šç‹€æ…‹æ±ºå®šæ˜¯å¦é¡¯ç¤ºåˆ†æå…§å®¹
if st.session_state.analysis_started:
    tw_list = [x.strip() for x in tw_in.split(',') if x.strip()]
    us_list = [x.strip().upper() for x in us_in.split(',') if x.strip()]
    
    with st.spinner('æ­£åœ¨å¾ Yahoo Finance ç¯€é»æŠ“å–å…¨çƒè¤‡æ¬Šæ•¸æ“š...'):
        raw_data = fetch_stock_data(tw_list, us_list, start_date, end_date)
        
        if not raw_data:
            st.error("âŒ æ‰€æœ‰ä¾†æºå‡é€£ç·šå¤±æ•—ã€‚")
            st.stop()
            
        df_prices = pd.DataFrame(raw_data).ffill().dropna()
        returns = df_prices.pct_change().replace([np.inf, -np.inf], np.nan).dropna()

    st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df_prices.columns)} æª”è³‡ç”¢æ•¸æ“šï¼")
    st.download_button("ğŸ“¥ ä¸‹è¼‰èª¿æ•´å¾Œæ•¸æ“š (CSV)", df_prices.to_csv().encode('utf-8'), "data.csv")

    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["ğŸ“Š çµ±è¨ˆ", "ğŸ”— ç›¸é—œæ€§", "ğŸ’° æ¨¡æ“¬", "ğŸ“ å¸‚å ´æ¨¡å‹", "âš–ï¸ æ•ˆç‡å‰ç·£", "ğŸ”® é æ¸¬", "ğŸš¨ (é»‘å¤©éµ)å£“åŠ›æ¸¬è©¦"])

    with tab1:
        st.subheader("ğŸ“‹ çµ±è¨ˆç‰¹å¾µ")
        res_df = pd.DataFrame(index=returns.columns)
        total_days = (df_prices.index[-1] - df_prices.index[0]).days
        years = max(total_days / 365.25, 0.1) 
        
        res_df['å¹´åŒ–å ±é…¬'] = (df_prices.iloc[-1] / df_prices.iloc[0]) ** (1 / years) - 1
        res_df['å¹´åŒ–æ³¢å‹•'] = returns.std() * np.sqrt(252)
        res_df['å¤æ™®æ¯”ç‡'] = (res_df['å¹´åŒ–å ±é…¬'] - rf_rate) / res_df['å¹´åŒ–æ³¢å‹•']
        res_df['æœ€å¤§å›æ’¤'] = [calculate_mdd(df_prices[c])[0] for c in df_prices.columns]
        
        res_df['ç¬¦åˆå¸¸æ…‹'] = [("âœ… æ˜¯" if stats.jarque_bera(returns[c])[1] > 0.05 else "âŒ å¦") for c in returns.columns]
        
        numeric_cols = ['å¹´åŒ–å ±é…¬', 'å¹´åŒ–æ³¢å‹•', 'å¤æ™®æ¯”ç‡', 'æœ€å¤§å›æ’¤']
        st.dataframe(res_df.style.format({c: "{:.2%}" for c in numeric_cols}), use_container_width=True)
        
        cols = st.columns(2)
        for i, col in enumerate(returns.columns):
            with cols[i%2]:
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.hist(returns[col], bins=40, density=True, alpha=0.7, color='steelblue')
                ax.set_title(f"{col} Distribution of Returns")
                st.pyplot(fig)

    with tab2:
        st.subheader("ğŸ”— ç›¸é—œæ€§çŸ©é™£")
        fig, ax = plt.subplots(figsize=(10, 8))
        corr = returns.corr()
        im = ax.imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)
        plt.colorbar(im)
        ax.set_xticks(range(len(corr.columns))); ax.set_xticklabels(corr.columns, rotation=45)
        ax.set_yticks(range(len(corr.columns))); ax.set_yticklabels(corr.columns)
        st.pyplot(fig)

    with tab3:
        st.subheader("ğŸ’° è²¡å¯Œç´¯ç©æ›²ç·š")
        st.line_chart((1 + returns).cumprod() * initial_cap)

    with tab4:
        st.subheader("ğŸ“ å¸‚å ´æ¨¡å‹ (Beta)")
        beta_data = []
        for s in [c for c in returns.columns if c not in ['0050', 'SPY']]:
            if s.isdigit() and '0050' in returns.columns:
                mkt_ref = '0050'
            elif not s.isdigit() and 'SPY' in returns.columns:
                mkt_ref = 'SPY'
            else: continue
            common_df = pd.concat([returns[mkt_ref], returns[s]], axis=1).dropna()
            if len(common_df) > 10:
                slope, _, r_val, _, _ = stats.linregress(common_df.iloc[:,0], common_df.iloc[:,1])
                beta_data.append({"Asset": s, "Benchmark": mkt_ref, "Beta": slope, "R2": r_val**2})
        st.table(pd.DataFrame(beta_data))

# --- åœ¨ tab5 ä¹‹å‰å…ˆæº–å‚™å¥½æœ€ä½³åŒ–æ‰€éœ€çš„æ•¸æ“šèˆ‡å‡½æ•¸ ---
    import scipy.optimize as sco
    import matplotlib.ticker as mtick # å¼•å…¥ç™¾åˆ†æ¯”æ ¼å¼åŒ–å·¥å…·

    # 1. è¨ˆç®—æ—¥å‡å ±é…¬èˆ‡å…±è®Šç•°çŸ©é™£
    mu = returns.mean()
    S = returns.cov()

    def get_portfolio_performance(weights, mu, S, rf_rate):
        # è¨ˆç®—å¹´åŒ–å ±é…¬èˆ‡å¹´åŒ–æ³¢å‹•
        p_ret = np.sum(mu * weights) * 252
        p_std = np.sqrt(np.dot(weights.T, np.dot(S * 252, weights)))
        return p_ret, p_std

    def neg_sharpe_ratio(weights, mu, S, rf_rate):
        p_ret, p_std = get_portfolio_performance(weights, mu, S, rf_rate)
        return -(p_ret - rf_rate) / p_std

    def minimize_volatility(weights, mu, S, rf_rate):
        return get_portfolio_performance(weights, mu, S, rf_rate)[1]

with tab5:
    st.subheader("âš–ï¸ æ•ˆç‡å‰ç·£èˆ‡æœ€ä½³é…ç½® (Scipy Optimize)")
    
    # --- 1. è¨ˆç®—é‚è¼¯ (å®Œå…¨ä¿ç•™æ‚¨çš„åŸå§‹é‚è¼¯) ---
    num_assets = len(returns.columns)
    sim_res = np.zeros((3, num_simulations))
    for i in range(num_simulations):
        w = np.random.random(num_assets)
        w /= np.sum(w)
        p_ret, p_std = get_portfolio_performance(w, mu, S, rf_rate)
        sim_res[0,i] = p_std
        sim_res[1,i] = p_ret
        sim_res[2,i] = (p_ret - rf_rate) / p_std 

    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    bounds = tuple((0, 1) for _ in range(num_assets))
    init_guess = num_assets * [1. / num_assets,]

    opt_sharpe = sco.minimize(neg_sharpe_ratio, init_guess, args=(mu, S, rf_rate), 
                              method='SLSQP', bounds=bounds, constraints=constraints)
    sharpe_ret, sharpe_vol = get_portfolio_performance(opt_sharpe.x, mu, S, rf_rate)
    best_weights = opt_sharpe.x 

    opt_vol = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                           method='SLSQP', bounds=bounds, constraints=constraints)
    min_vol_ret, min_vol_vol = get_portfolio_performance(opt_vol.x, mu, S, rf_rate)

    target_returns = np.linspace(min_vol_ret, max(sharpe_ret, sim_res[1].max()) * 1.05, 50)
    frontier_vol = []
    for t_ret in target_returns:
        cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                {'type': 'eq', 'fun': lambda x: get_portfolio_performance(x, mu, S, rf_rate)[0] - t_ret})
        res = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                           method='SLSQP', bounds=bounds, constraints=cons)
        frontier_vol.append(res.fun if res.success else np.nan)

    # --- 2. ä¸Šæ–¹å€å¡Šï¼šæ•ˆç‡å‰ç·£å¤§åœ– (å–®ç¨ä¸€æ’) ---
    fig, ax = plt.subplots(figsize=(12, 6))
    sc = ax.scatter(sim_res[0,:], sim_res[1,:], c=sim_res[2,:], cmap='viridis', s=15, alpha=0.4, label='Random Portfolios')
    plt.colorbar(sc, label='Sharpe Ratio')
    ax.plot(frontier_vol, target_returns, 'b-', linewidth=2.5, label='Efficient Frontier')
    
    asset_ret = mu * 252
    asset_vol = np.sqrt(np.diag(S)) * np.sqrt(252)
    ax.scatter(asset_vol, asset_ret, marker='o', color='grey', s=50, label='Individual Assets')
    for i, txt in enumerate(returns.columns):
        ax.annotate(txt, (asset_vol[i], asset_ret[i]), xytext=(5,0), textcoords='offset points')

    ax.scatter(min_vol_vol, min_vol_ret, marker='*', color='orange', s=250, edgecolors='black', label='Min Volatility (MVP)', zorder=10)
    ax.scatter(sharpe_vol, sharpe_ret, marker='*', color='purple', s=250, edgecolors='black', label='Max Sharpe (MSR)', zorder=10)
    
    cml_x = np.linspace(0, max(sim_res[0].max(), sharpe_vol)*1.2, 100)
    cml_slope = (sharpe_ret - rf_rate) / sharpe_vol
    ax.plot(cml_x, rf_rate + cml_slope * cml_x, 'g--', label='Capital Market Line (CML)', alpha=0.7)

    ax.set_title(f"Efficient Frontier & Optimal Portfolios (Rf={rf_rate*100:.2f}%)", fontsize=14)
    ax.set_xlabel("Annualized Volatility (Risk)")
    ax.set_ylabel("Annualized Expected Return")
    ax.legend(loc='best')
    st.pyplot(fig)

    st.markdown("---")

    # --- 3. ä¸‹æ–¹å€å¡Šï¼šå…©å€‹åœ“é¤…åœ–ä¸¦æ’ ---
    col_left, col_right = st.columns(2)

    with col_left:
        st.write("#### ğŸ† Maximum Sharpe Ratio (MSR)")
        df_sharpe = pd.DataFrame({'Asset': returns.columns, 'Weight': best_weights * 100})
        df_sharpe = df_sharpe.sort_values(by='Weight', ascending=False)
        fig_pie1, ax_pie1 = plt.subplots(figsize=(4, 4))
        ax_pie1.pie(df_sharpe['Weight'], labels=df_sharpe['Asset'], autopct='%1.1f%%', startangle=90)
        st.pyplot(fig_pie1)
        st.dataframe(df_sharpe.style.format({'Weight': '{:.2f}%'}), hide_index=True, use_container_width=True)
        st.info(f"Ret: {sharpe_ret:.2%} / Vol: {sharpe_vol:.2%}")

    with col_right:
        st.write("#### ğŸ›¡ï¸ Minimum Variance Portfolio (MVP)")
        df_mvp = pd.DataFrame({'Asset': returns.columns, 'Weight': opt_vol.x * 100})
        df_mvp = df_mvp.sort_values(by='Weight', ascending=False)
        fig_pie2, ax_pie2 = plt.subplots(figsize=(4, 4))
        ax_pie2.pie(df_mvp['Weight'], labels=df_mvp['Asset'], autopct='%1.1f%%', startangle=90)
        st.pyplot(fig_pie2)
        st.dataframe(df_mvp.style.format({'Weight': '{:.2f}%'}), hide_index=True, use_container_width=True)
        st.info(f"Ret: {min_vol_ret:.2%} / Vol: {min_vol_vol:.2%}")
            
# --- TAB 6: æ··åˆèªè¨€ç‰ˆ (ä»‹é¢å„ªåŒ–ï¼šå­—é«”ç¸®å° / æ˜ç¢ºæ¨™ç¤º MSR) ---
with tab6:
    # ä¿®æ”¹ 1: å°‡æ¨™é¡Œæ”¹å°ä¸€é» (åŸæœ¬æ˜¯ subheaderï¼Œç¾åœ¨æ”¹ç”¨ markdown ####)
    st.markdown("#### ğŸ”® æœ€ä½³æŠ•è³‡çµ„åˆæœªä¾†é æ¸¬ (GBM æ¨¡å‹)")

    # 1. æ¨¡æ“¬åƒæ•¸è¨­å®š
    n_sim_total = 1000  # æ¨¡æ“¬ 1000 æ¬¡
    n_plot = 50         # ç•«åœ–åªç•«å‰ 50 æ¢
    
    # 2. æº–å‚™çµ„åˆåƒæ•¸ (ä¾†è‡ª Tab 5 çš„æœ€ä½³æ¬Šé‡ - MSR)
    port_returns_series = (returns * best_weights).sum(axis=1)
    mu_p = port_returns_series.mean() * 252
    sigma_p = port_returns_series.std() * np.sqrt(252)
    
    s0 = initial_cap
    dt = 1/252
    
    # 3. åŸ·è¡Œ GBM éš¨æ©Ÿæ¼«æ­¥æ¨¡æ“¬
    sim_paths = np.zeros((forecast_len, n_sim_total))
    sim_paths[0] = s0
    
    drift = (mu_p - 0.5 * sigma_p**2) * dt
    shock = sigma_p * np.sqrt(dt)
    
    z_matrix = np.random.normal(0, 1, (forecast_len - 1, n_sim_total))
    
    for t in range(1, forecast_len):
        sim_paths[t] = sim_paths[t-1] * np.exp(drift + shock * z_matrix[t-1])
        
    # 4. ç¹ªè£½è·¯å¾‘åœ–
    st.write(f"**ğŸ“ˆ è³‡ç”¢è·¯å¾‘æ¨¡æ“¬ (é¡¯ç¤ºå‰ {n_plot} æ¢ / å…± {n_sim_total} æ¬¡)**")
    st.line_chart(sim_paths[:, :n_plot])
    
    # ä¿®æ”¹ 2: åœ¨åœ–è¡¨ä¸‹æ–¹åŠ å…¥å°å­—çš„èªªæ˜ (Description)
    st.markdown(f"""
    <div style="font-size: 12px; color: #666; margin-top: -10px; margin-bottom: 20px;">
        â„¹ï¸ <b>æ¨¡æ“¬åŸºæº–èªªæ˜ï¼š</b> æ­¤é æ¸¬æ˜¯åŸºæ–¼ Tab 5 ç®—å‡ºçš„ <b>ã€Œæœ€å¤§å¤æ™®æ¯”ç‡çµ„åˆ (Max Sharpe Ratio)ã€</b> é€²è¡Œæ¨ä¼°ã€‚<br>
        åƒæ•¸è¨­å®šï¼šå¹´åŒ–é æœŸå ±é…¬ (Î¼) = <b>{mu_p:.2%}</b>ï¼Œå¹´åŒ–æ³¢å‹•ç‡ (Ïƒ) = <b>{sigma_p:.2%}</b>ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # 5. çµ±è¨ˆæ•¸æ“šè¨ˆç®—
    final_values = sim_paths[-1, :]
    
    # (1) åŸºç¤çµ±è¨ˆ
    mean_end = np.mean(final_values)
    median_end = np.median(final_values)
    max_profit = np.max(final_values) - s0
    prob_profit = np.sum(final_values > s0) / n_sim_total
    
    # (2) é¢¨éšªæº¢é…¬
    rf_end_value = s0 * np.exp(rf_rate * (forecast_len / 252))
    risk_premium = mean_end - rf_end_value
    
    # (3) å¹´åŒ–æ³¢å‹•ç‡
    log_returns = np.log(final_values / s0)
    realized_vol = np.std(log_returns) / np.sqrt(forecast_len / 252)
    
    # (4) é¢¨éšªå€¼
    var_95 = np.percentile(final_values, 5)
    cvar_95 = final_values[final_values <= var_95].mean()

    # 6. é¡¯ç¤ºçµ±è¨ˆæŒ‡æ¨™ (æ¨™é¡Œä¹Ÿç¸®å°)
    st.markdown("#### ğŸ“Š é æ¸¬çµæœçµ±è¨ˆåˆ†æ")
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    
    with col_stat1:
        st.metric("å¹³å‡æœŸæœ«è³‡ç”¢", f"${mean_end:,.0f}", delta=f"{(mean_end/s0 -1):.2%}")
        st.metric("ä¸­ä½æ•¸è³‡ç”¢", f"${median_end:,.0f}")
        st.metric("å¹´åŒ–æ³¢å‹•ç‡", f"{realized_vol:.2%}")

    with col_stat2:
        st.metric("æ­£å ±é…¬æ©Ÿç‡ (>æœ¬é‡‘)", f"{prob_profit:.1%}")
        st.metric("é æœŸæœ€å¤§ç²åˆ© (æ·¨åˆ©)", f"${max_profit:,.0f}")
        st.metric("é æœŸé¢¨éšªæº¢é…¬", f"${risk_premium:,.0f}", help=f"å¹³å‡çµ‚å€¼ - ç„¡é¢¨éšªåˆ©ç‡çµ‚å€¼ (${rf_end_value:,.0f})")

    with col_stat3:
        st.markdown("**âš ï¸ ä¸‹æª”é¢¨éšª (Tail Risk)**") # æ”¹ç”¨ markdown ç²—é«”å–ä»£ subheader
        st.metric("é¢¨éšªå€¼ VaR (95%)", f"${var_95:,.0f}", delta=f"{(var_95/s0 -1):.2%}", delta_color="inverse")
        st.caption(f"æ¢ä»¶é¢¨éšªå€¼ CVaR (æœ€å·®5%å¹³å‡): ${cvar_95:,.0f}")

    # 7. åˆ†ä½ˆæ“¬åˆåˆ†æ
    st.markdown("#### ğŸ“‰ æ©Ÿç‡åˆ†ä½ˆæ“¬åˆåˆ†æ")
    
    dist_candidates = {
        "Log-Normal": stats.lognorm,
        "Gamma": stats.gamma,
        "Student's t": stats.t,
        "Chi-Squared": stats.chi2,
        "Beta": stats.beta
    }
    
    fit_results = []
    
    with st.spinner("æ­£åœ¨è¨ˆç®—æœ€ä½³æ“¬åˆæ¨¡å‹..."):
        for name, dist in dist_candidates.items():
            try:
                params = dist.fit(final_values)
                D, p = stats.kstest(final_values, dist.cdf, args=params)
                fit_results.append({
                    "Distribution": name,
                    "D_Statistic": D,
                    "p_value": p,
                    "params": params,
                    "model": dist
                })
            except:
                continue

    fit_results.sort(key=lambda x: x['D_Statistic'])
    best_fit = fit_results[0]
    
    col_plot, col_rank = st.columns([3, 1])
    
    with col_plot:
        fig_hist, ax_hist = plt.subplots(figsize=(10, 6))
        
        ax_hist.hist(final_values, bins=60, density=True, alpha=0.5, color='lightgray', label='Simulated Data', edgecolor='white')
        
        x_fit = np.linspace(np.min(final_values), np.max(final_values), 200)
        winner_model = best_fit['model']
        winner_params = best_fit['params']
        pdf_fit = winner_model.pdf(x_fit, *winner_params)
        
        ax_hist.plot(x_fit, pdf_fit, 'r-', lw=3, label=f"Best Fit: {best_fit['Distribution']}")
        
        ax_hist.axvline(s0, color='black', linestyle='--', linewidth=1, label='Initial Capital')
        ax_hist.axvline(mean_end, color='blue', linestyle=':', linewidth=1.5, label='Mean Value')

        ax_hist.set_title(f"Forecast Distribution & Best Fit Model ({forecast_len} Days)")
        ax_hist.set_xlabel("Portfolio Value ($)")
        ax_hist.set_ylabel("Probability Density")
        ax_hist.legend()
        
        import matplotlib.ticker as mticker
        ax_hist.xaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))
        
        st.pyplot(fig_hist)
        
    with col_rank:
        st.markdown("**ğŸ† æ“¬åˆæº–ç¢ºåº¦æ’å**")
        st.caption("KS çµ±è¨ˆé‡ (è¶Šä½è¶Šæº–)")
        
        rank_data = []
        for res in fit_results:
            rank_data.append({
                "åˆ†ä½ˆæ¨¡å‹": res['Distribution'],
                "KS å·®ç•°å€¼ (D)": f"{res['D_Statistic']:.4f}"
            })
        st.dataframe(pd.DataFrame(rank_data), hide_index=True)
        
        # ä¿®æ”¹ 3: æœ€å¾Œçš„ç¸½çµä¹Ÿæ”¹ç”¨å°å­— caption
        st.caption(f"âœ… ç¶“çµ±è¨ˆæª¢å®šï¼Œæœ€ä½³æ“¬åˆæ¨¡å‹ç‚ºï¼š **{best_fit['Distribution']}**")        
        # --- TAB 7: å£“åŠ›æ¸¬è©¦ ---
        with tab7:
            st.subheader("ğŸš¨ æŠ•è³‡çµ„åˆå£“åŠ›æ¸¬è©¦ (Stress Test)")
            
            # 1. è¨ˆç®—çµ„åˆçš„åŠ æ¬Š Beta (åæ˜ çµ„åˆå°å¸‚å ´çš„æ•æ„Ÿåº¦)
            # é€™è£¡å¾ä½  TAB 4 çš„ beta_data æå–è³‡æ–™
            if len(beta_data) > 0:
                df_beta = pd.DataFrame(beta_data)
                # å»ºç«‹æ¬Šé‡å­—å…¸æ–¹ä¾¿æŸ¥è©¢
                weight_dict = dict(zip(returns.columns, best_weights))
                # è¨ˆç®—çµ„åˆ Beta = Î£ (æ¬Šé‡ * å€‹è‚¡ Beta)
                df_beta['Weighted Beta'] = df_beta.apply(lambda x: x['Beta'] * weight_dict.get(x['Asset'], 0), axis=1)
                port_beta = df_beta['Weighted Beta'].sum()
            else:
                port_beta = 1.0 # é è¨­å€¼
                
            col1, col2 = st.columns([2, 3])
            
            with col1:
                st.write("**è‡ªå®šç¾©å¸‚å ´è¡æ“Šé æ¸¬**")
                mkt_shock = st.slider("å‡è¨­å¤§ç›¤(å¸‚å ´åŸºæº–)ä¸‹è·Œ (%)", -50, 0, -10)
                
                # é ä¼°æå¤± = æœ¬é‡‘ * å¸‚å ´è·Œå¹… * çµ„åˆ Beta
                est_loss_pct = (mkt_shock / 100) * port_beta
                est_loss_amt = initial_cap * est_loss_pct
                
                st.metric("é ä¼°çµ„åˆè·Œå¹…", f"{est_loss_pct:.2%}", delta=f"{est_loss_pct:.2%}")
                st.metric("é ä¼°æå¤±é‡‘é¡", f"${est_loss_amt:,.0f}")
                
            with col2:
                st.write("**æ­·å²æ¥µç«¯æƒ…å¢ƒæ¨¡æ“¬**")
                scenarios = {
                    "2008 é‡‘èæµ·å˜¯ (å‡è¨­å¤§ç›¤ -20%)": -0.20,
                    "2020 ç–«æƒ…å´©ç›¤ (å‡è¨­å¤§ç›¤ -15%)": -0.15,
                    "2022 å‡æ¯ç¸®è¡¨ (å‡è¨­å¤§ç›¤ -10%)": -0.10,
                    "å¾®å¹…ä¿®æ­£ (å‡è¨­å¤§ç›¤ -5%)": -0.05
                }
                
                scene_data = []
                for name, shock in scenarios.items():
                    loss_pct = shock * port_beta
                    scene_data.append({
                        "æƒ…å¢ƒ": name,
                        "å¤§ç›¤è·Œå¹…": f"{shock:.0%}",
                        "çµ„åˆé ä¼°è·Œå¹…": f"{loss_pct:.2%}",
                        "é ä¼°æå¤±é‡‘é¡": f"${initial_cap * loss_pct:,.0f}"
                    })
                
                st.table(pd.DataFrame(scene_data))
    
            st.info(f"ğŸ’¡ è¨»ï¼šç›®å‰çµ„åˆçš„åŠ æ¬Š Beta ç‚º **{port_beta:.2f}**ã€‚é€™ä»£è¡¨ç•¶å¤§ç›¤ä¸‹è·Œ 1% æ™‚ï¼Œé è¨ˆä½ çš„çµ„åˆæœƒéš¨ä¹‹è®Šå‹• {abs(port_beta):.2f}%ã€‚")







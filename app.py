import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import yfinance as yf
from datetime import datetime, timedelta

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="å…¨çƒæŠ•è³‡çµ„åˆåˆ†æç³»çµ±", layout="wide", page_icon="ğŸ“ˆ")

# è¨­å®šä¸­æ–‡å­—é«”
plt.style.use('bmh')
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

# --- 2. æ ¸å¿ƒè¨ˆç®—å‡½æ•¸ ---
def calculate_mdd(series):
    """è¨ˆç®—æœ€å¤§å›æ’¤"""
    cum_max = series.cummax()
    drawdown = (series - cum_max) / cum_max
    return drawdown.min(), drawdown

# --- 3. å¼·åŒ–å‹æ•¸æ“šæŠ“å–å‡½æ•¸ ---
@st.cache_data(ttl=3600)
def fetch_stock_data(tickers_tw, tickers_us, start, end):
    data_dict = {}
    unique_tw = list(set(tickers_tw + ['0050']))
    unique_us = list(set(tickers_us + ['SPY']))
    
    for s in unique_tw:
        if not s: continue
        try:
            ticker = f"{s}.TW"
            yf_obj = yf.Ticker(ticker)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"å°è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")

    for s in unique_us:
        if not s: continue
        try:
            yf_obj = yf.Ticker(s)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"ç¾è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")
    return data_dict

# --- 4. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header('ğŸ¯ æ¨™çš„è¨­å®š')
    tw_in = st.text_input('å°è‚¡ä»£è™Ÿ', '1215,1419,2430,2891,9918')
    us_in = st.text_input('ç¾è‚¡ä»£è™Ÿ', 'DBC,GLD,SPY,VCIT,VNQ,VTV,VUG')
    
    st.header('ğŸ“… æ™‚é–“èˆ‡è³‡é‡‘')
    start_date = st.date_input('é–‹å§‹æ—¥æœŸ', datetime.now() - timedelta(days=365*3))
    end_date = st.date_input('çµæŸæ—¥æœŸ', datetime.now())
    initial_cap = st.number_input('æœ¬é‡‘', value=100000)
    rf_rate = st.number_input('ç„¡é¢¨éšªåˆ©ç‡ (%)', value=4.0) / 100
    
    st.header('ğŸ² æ¨¡æ“¬è¨­å®š')
    num_simulations = st.slider('è’™åœ°å¡ç¾…æ¬¡æ•¸', 1000, 5000, 2000)
    forecast_len = st.slider('é æ¸¬å¤©æ•¸', 30, 365, 180)

# --- 5. ä¸»ç¨‹å¼åŸ·è¡Œ ---

# 1. åˆå§‹åŒ– Session State ç‹€æ…‹ï¼ˆé˜²æ­¢æ‹‰æ¡¿è§¸ç™¼é‡æ–°æ•´ç†å°è‡´ç•«é¢æ¶ˆå¤±ï¼‰
if 'analysis_started' not in st.session_state:
    st.session_state.analysis_started = False

# 2. é»æ“ŠæŒ‰éˆ•å¾Œï¼Œå°‡ç‹€æ…‹è¨­ç‚º True
if st.sidebar.button('ğŸš€ å•Ÿå‹•å…¨æ–¹ä½åˆ†æ', type="primary"):
    st.session_state.analysis_started = True

# 3. æ ¹æ“šç‹€æ…‹æ±ºå®šæ˜¯å¦é¡¯ç¤ºåˆ†æå…§å®¹
if st.session_state.analysis_started:
    tw_list = [x.strip() for x in tw_in.split(',') if x.strip()]
    us_list = [x.strip().upper() for x in us_in.split(',') if x.strip()]
    
    with st.spinner('æ­£åœ¨å¾ Yahoo Finance ç¯€é»æŠ“å–å…¨çƒè¤‡æ¬Šæ•¸æ“š...'):
        raw_data = fetch_stock_data(tw_list, us_list, start_date, end_date)
        
        if not raw_data:
            st.error("âŒ æ‰€æœ‰ä¾†æºå‡é€£ç·šå¤±æ•—ã€‚")
            st.stop()
            
        df_prices = pd.DataFrame(raw_data).ffill().dropna()
        returns = df_prices.pct_change().replace([np.inf, -np.inf], np.nan).dropna()

    st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df_prices.columns)} æª”è³‡ç”¢æ•¸æ“šï¼")
    st.download_button("ğŸ“¥ ä¸‹è¼‰èª¿æ•´å¾Œæ•¸æ“š (CSV)", df_prices.to_csv().encode('utf-8'), "data.csv")

    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["ğŸ“Š çµ±è¨ˆ", "ğŸ”— ç›¸é—œæ€§", "ğŸ’° æ¨¡æ“¬", "ğŸ“ å¸‚å ´æ¨¡å‹", "âš–ï¸ æ•ˆç‡å‰ç·£", "ğŸ”® é æ¸¬", "ğŸš¨ (é»‘å¤©éµ)å£“åŠ›æ¸¬è©¦"])

    with tab1:
        st.subheader("ğŸ“‹ çµ±è¨ˆç‰¹å¾µ")
        res_df = pd.DataFrame(index=returns.columns)
        total_days = (df_prices.index[-1] - df_prices.index[0]).days
        years = max(total_days / 365.25, 0.1) 
        
        res_df['å¹´åŒ–å ±é…¬'] = (df_prices.iloc[-1] / df_prices.iloc[0]) ** (1 / years) - 1
        res_df['å¹´åŒ–æ³¢å‹•'] = returns.std() * np.sqrt(252)
        res_df['å¤æ™®æ¯”ç‡'] = (res_df['å¹´åŒ–å ±é…¬'] - rf_rate) / res_df['å¹´åŒ–æ³¢å‹•']
        res_df['æœ€å¤§å›æ’¤'] = [calculate_mdd(df_prices[c])[0] for c in df_prices.columns]
        
        res_df['ç¬¦åˆå¸¸æ…‹'] = [("âœ… æ˜¯" if stats.jarque_bera(returns[c])[1] > 0.05 else "âŒ å¦") for c in returns.columns]
        
        numeric_cols = ['å¹´åŒ–å ±é…¬', 'å¹´åŒ–æ³¢å‹•', 'å¤æ™®æ¯”ç‡', 'æœ€å¤§å›æ’¤']
        st.dataframe(res_df.style.format({c: "{:.2%}" for c in numeric_cols}), use_container_width=True)
        
        cols = st.columns(2)
        for i, col in enumerate(returns.columns):
            with cols[i%2]:
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.hist(returns[col], bins=40, density=True, alpha=0.7, color='steelblue')
                ax.set_title(f"{col} Distribution of Returns")
                st.pyplot(fig)

    with tab2:
        st.subheader("ğŸ”— ç›¸é—œæ€§çŸ©é™£")
        fig, ax = plt.subplots(figsize=(10, 8))
        corr = returns.corr()
        im = ax.imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)
        plt.colorbar(im)
        ax.set_xticks(range(len(corr.columns))); ax.set_xticklabels(corr.columns, rotation=45)
        ax.set_yticks(range(len(corr.columns))); ax.set_yticklabels(corr.columns)
        st.pyplot(fig)

    with tab3:
        st.subheader("ğŸ’° è²¡å¯Œç´¯ç©æ›²ç·š")
        st.line_chart((1 + returns).cumprod() * initial_cap)

    with tab4:
        st.subheader("ğŸ“ å¸‚å ´æ¨¡å‹ (Beta)")
        beta_data = []
        for s in [c for c in returns.columns if c not in ['0050', 'SPY']]:
            if s.isdigit() and '0050' in returns.columns:
                mkt_ref = '0050'
            elif not s.isdigit() and 'SPY' in returns.columns:
                mkt_ref = 'SPY'
            else: continue
            common_df = pd.concat([returns[mkt_ref], returns[s]], axis=1).dropna()
            if len(common_df) > 10:
                slope, _, r_val, _, _ = stats.linregress(common_df.iloc[:,0], common_df.iloc[:,1])
                beta_data.append({"Asset": s, "Benchmark": mkt_ref, "Beta": slope, "R2": r_val**2})
        st.table(pd.DataFrame(beta_data))

    # --- é‡é ­æˆ²ï¼šä¿®æ”¹å¾Œçš„ Tab 5 ---
    with tab5:
        st.subheader("âš–ï¸ æ•ˆç‡å‰ç·£èˆ‡æœ€ä½³é…ç½® (Scipy Optimize)")
        
        col_main, col_info = st.columns([3, 1])
        
        with col_main:
            # 1. è’™åœ°å¡ç¾…æ¨¡æ“¬ (ä½œç‚ºèƒŒæ™¯é›²)
            num_assets = len(returns.columns)
            sim_res = np.zeros((3, num_simulations))
            for i in range(num_simulations):
                weights = np.random.random(num_assets)
                weights /= np.sum(weights)
                p_ret, p_std = get_portfolio_performance(weights, mu, S, rf_rate)
                sim_res[0,i] = p_std
                sim_res[1,i] = p_ret
                sim_res[2,i] = (p_ret - rf_rate) / p_std # Sharpe

            # 2. æ•¸å€¼æœ€ä½³åŒ–æ±‚è§£ (SLSQP)
            constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
            bounds = tuple((0, 1) for _ in range(num_assets))
            init_guess = num_assets * [1. / num_assets,]

            # A. æœ€å¤§å¤æ™®æ¯”ç‡çµ„åˆ (Tangency Portfolio)
            opt_sharpe = sco.minimize(neg_sharpe_ratio, init_guess, args=(mu, S, rf_rate), 
                                      method='SLSQP', bounds=bounds, constraints=constraints)
            sharpe_ret, sharpe_vol = get_portfolio_performance(opt_sharpe.x, mu, S, rf_rate)
            best_weights_global = opt_sharpe.x # æ›´æ–°å…¨åŸŸæœ€ä½³æ¬Šé‡ä¾›å¾ŒçºŒä½¿ç”¨

            # B. æœ€å°æ³¢å‹•ç‡çµ„åˆ (MVP)
            opt_vol = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                                   method='SLSQP', bounds=bounds, constraints=constraints)
            min_vol_ret, min_vol_vol = get_portfolio_performance(opt_vol.x, mu, S, rf_rate)

            # C. ç¹ªè£½æ•ˆç‡å‰ç·£æ›²ç·š (Efficient Frontier)
            target_returns = np.linspace(min_vol_ret, max(sharpe_ret, sim_res[1].max()) * 1.05, 50)
            frontier_vol = []
            
            for t_ret in target_returns:
                cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                        {'type': 'eq', 'fun': lambda x: get_portfolio_performance(x, mu, S, rf_rate)[0] - t_ret})
                res = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                                   method='SLSQP', bounds=bounds, constraints=cons)
                if res.success:
                    frontier_vol.append(res.fun) # res.fun is volatility here
                else:
                    frontier_vol.append(np.nan)

            # 3. ç¹ªåœ–
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # (1) éš¨æ©Ÿæ¨¡æ“¬é» (èƒŒæ™¯)
            sc = ax.scatter(sim_res[0,:], sim_res[1,:], c=sim_res[2,:], cmap='viridis', s=10, alpha=0.3, label='Random Portfolios')
            plt.colorbar(sc, label='Sharpe Ratio')
            
            # (2) æ•ˆç‡å‰ç·£ç·š
            ax.plot(frontier_vol, target_returns, 'b-', linewidth=2.5, label='Efficient Frontier')
            
            # (3) å€‹åˆ¥è³‡ç”¢é»
            asset_ret = mu * 252
            asset_vol = np.sqrt(np.diag(S)) * np.sqrt(252)
            ax.scatter(asset_vol, asset_ret, marker='o', color='grey', s=50, label='Assets')
            for i, txt in enumerate(returns.columns):
                ax.annotate(txt, (asset_vol[i], asset_ret[i]), xytext=(5,0), textcoords='offset points')

            # (4) æ¨™è¨˜é—œéµçµ„åˆ
            # MVP
            ax.scatter(min_vol_vol, min_vol_ret, marker='*', color='orange', s=250, edgecolors='black', label='Min Volatility (MVP)')
            # Max Sharpe
            ax.scatter(sharpe_vol, sharpe_ret, marker='*', color='purple', s=250, edgecolors='black', label='Max Sharpe (Tangency)')

            # (5) è³‡æœ¬å¸‚å ´ç·š (CML)
            cml_x = np.linspace(0, max(sim_res[0].max(), sharpe_vol)*1.2, 100)
            cml_slope = (sharpe_ret - rf_rate) / sharpe_vol
            cml_y = rf_rate + cml_slope * cml_x
            ax.plot(cml_x, cml_y, 'g--', label='Capital Market Line (CML)', alpha=0.7)

            # è¨­å®šåº§æ¨™è»¸æ ¼å¼
            ax.set_title(f'æ•ˆç‡å‰ç·£èˆ‡æœ€ä½³é…ç½® (Rf={rf_rate*100}%)')
            ax.set_xlabel('Annualized Volatility (Risk)')
            ax.set_ylabel('Annualized Expected Return')
            ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))
            ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))
            ax.set_xlim(left=0)
            ax.legend(loc='best')
            
            st.pyplot(fig)

        with col_info:
            st.write("### ğŸ† æœ€ä½³é…ç½® (Max Sharpe)")
            df_weights = pd.DataFrame({'è³‡ç”¢': returns.columns, 'æ¯”ä¾‹': best_weights_global * 100})
            df_weights = df_weights.sort_values(by='æ¯”ä¾‹', ascending=False)
            
            # åœ“é¤…åœ–
            fig_pie, ax_pie = plt.subplots(figsize=(4, 4))
            ax_pie.pie(df_weights['æ¯”ä¾‹'], labels=df_weights['è³‡ç”¢'], autopct='%1.1f%%', startangle=90)
            st.pyplot(fig_pie)
            
            st.dataframe(df_weights.style.format({'æ¯”ä¾‹': '{:.2f}%'}), hide_index=True)
            
            st.markdown("---")
            st.metric("é æœŸå¹´åŒ–å ±é…¬", f"{sharpe_ret:.2%}")
            st.metric("é æœŸå¹´åŒ–æ³¢å‹•", f"{sharpe_vol:.2%}")
            st.metric("å¤æ™®æ¯”ç‡", f"{(sharpe_ret - rf_rate)/sharpe_vol:.2f}")

    # --- TAB 6 ä¿®æ”¹ï¼šåƒ…é‡å° TAB5 æœ€ä½³çµ„åˆé€²è¡Œé æ¸¬ ---
    with tab6:
        st.subheader("ğŸ”® æœ€ä½³æŠ•è³‡çµ„åˆæœªä¾†é æ¸¬ (GBM)")
        
        # 1. è¨ˆç®—æœ€ä½³çµ„åˆçš„æ­·å²å ±é…¬ç‡åºåˆ—
        port_returns_series = (returns * best_weights).sum(axis=1)
        
        # 2. å–å¾—çµ„åˆçš„å¹´åŒ–åƒæ•¸
        mu_p = port_returns_series.mean() * 252
        sigma_p = port_returns_series.std() * np.sqrt(252)
        s0 = initial_cap  # æ¨¡æ“¬èµ·é»è¨­å®šç‚ºåˆå§‹æœ¬é‡‘
        dt = 1/252
        
        # 3. åŸ·è¡Œ GBM æ¨¡æ“¬ (ç¶­æŒåŸæœ‰çš„ 50 æ¢è·¯å¾‘é‚è¼¯)
        sim_paths = np.zeros((forecast_len, 50))
        sim_paths[0] = s0
        
        drift = (mu_p - 0.5 * sigma_p**2) * dt
        shock = sigma_p * np.sqrt(dt)
        
        for t in range(1, forecast_len):
            z = np.random.normal(0, 1, 50)
            sim_paths[t] = sim_paths[t-1] * np.exp(drift + shock * z)
            
        # 4. ç¹ªè£½åœ–è¡¨
        st.line_chart(sim_paths)
        
        # 5. è¼¸å‡ºçµ„åˆé æ¸¬åŸºæº–è³‡è¨Š
        st.write(f"é æ¸¬åŸºæº–ï¼šTab 5 è¨ˆç®—ä¹‹æœ€ä½³å¤æ™®çµ„åˆ (MSR)")
        st.info(f"çµ„åˆå¹´åŒ–é æœŸå ±é…¬: {mu_p:.2%}, å¹´åŒ–æ³¢å‹•ç‡ (é¢¨éšª): {sigma_p:.2%}")
        
    # --- TAB 7: å£“åŠ›æ¸¬è©¦ ---
        with tab7:
            st.subheader("ğŸš¨ æŠ•è³‡çµ„åˆå£“åŠ›æ¸¬è©¦ (Stress Test)")
            
            # 1. è¨ˆç®—çµ„åˆçš„åŠ æ¬Š Beta (åæ˜ çµ„åˆå°å¸‚å ´çš„æ•æ„Ÿåº¦)
            # é€™è£¡å¾ä½  TAB 4 çš„ beta_data æå–è³‡æ–™
            if len(beta_data) > 0:
                df_beta = pd.DataFrame(beta_data)
                # å»ºç«‹æ¬Šé‡å­—å…¸æ–¹ä¾¿æŸ¥è©¢
                weight_dict = dict(zip(returns.columns, best_weights))
                # è¨ˆç®—çµ„åˆ Beta = Î£ (æ¬Šé‡ * å€‹è‚¡ Beta)
                df_beta['Weighted Beta'] = df_beta.apply(lambda x: x['Beta'] * weight_dict.get(x['Asset'], 0), axis=1)
                port_beta = df_beta['Weighted Beta'].sum()
            else:
                port_beta = 1.0 # é è¨­å€¼
                
            col1, col2 = st.columns([2, 3])
            
            with col1:
                st.write("**è‡ªå®šç¾©å¸‚å ´è¡æ“Šé æ¸¬**")
                mkt_shock = st.slider("å‡è¨­å¤§ç›¤(å¸‚å ´åŸºæº–)ä¸‹è·Œ (%)", -50, 0, -10)
                
                # é ä¼°æå¤± = æœ¬é‡‘ * å¸‚å ´è·Œå¹… * çµ„åˆ Beta
                est_loss_pct = (mkt_shock / 100) * port_beta
                est_loss_amt = initial_cap * est_loss_pct
                
                st.metric("é ä¼°çµ„åˆè·Œå¹…", f"{est_loss_pct:.2%}", delta=f"{est_loss_pct:.2%}")
                st.metric("é ä¼°æå¤±é‡‘é¡", f"${est_loss_amt:,.0f}")
                
            with col2:
                st.write("**æ­·å²æ¥µç«¯æƒ…å¢ƒæ¨¡æ“¬**")
                scenarios = {
                    "2008 é‡‘èæµ·å˜¯ (å‡è¨­å¤§ç›¤ -20%)": -0.20,
                    "2020 ç–«æƒ…å´©ç›¤ (å‡è¨­å¤§ç›¤ -15%)": -0.15,
                    "2022 å‡æ¯ç¸®è¡¨ (å‡è¨­å¤§ç›¤ -10%)": -0.10,
                    "å¾®å¹…ä¿®æ­£ (å‡è¨­å¤§ç›¤ -5%)": -0.05
                }
                
                scene_data = []
                for name, shock in scenarios.items():
                    loss_pct = shock * port_beta
                    scene_data.append({
                        "æƒ…å¢ƒ": name,
                        "å¤§ç›¤è·Œå¹…": f"{shock:.0%}",
                        "çµ„åˆé ä¼°è·Œå¹…": f"{loss_pct:.2%}",
                        "é ä¼°æå¤±é‡‘é¡": f"${initial_cap * loss_pct:,.0f}"
                    })
                
                st.table(pd.DataFrame(scene_data))
    
            st.info(f"ğŸ’¡ è¨»ï¼šç›®å‰çµ„åˆçš„åŠ æ¬Š Beta ç‚º **{port_beta:.2f}**ã€‚é€™ä»£è¡¨ç•¶å¤§ç›¤ä¸‹è·Œ 1% æ™‚ï¼Œé è¨ˆä½ çš„çµ„åˆæœƒéš¨ä¹‹è®Šå‹• {abs(port_beta):.2f}%ã€‚")





import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import yfinance as yf
from datetime import datetime, timedelta

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="å…¨çƒæŠ•è³‡çµ„åˆåˆ†æç³»çµ±", layout="wide", page_icon="ğŸ“ˆ")

# è¨­å®šä¸­æ–‡å­—é«”
plt.style.use('bmh')
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

# --- 2. æ ¸å¿ƒè¨ˆç®—å‡½æ•¸ ---
def calculate_mdd(series):
    """è¨ˆç®—æœ€å¤§å›æ’¤"""
    cum_max = series.cummax()
    drawdown = (series - cum_max) / cum_max
    return drawdown.min(), drawdown

# --- 3. å¼·åŒ–å‹æ•¸æ“šæŠ“å–å‡½æ•¸ ---
@st.cache_data(ttl=3600)
def fetch_stock_data(tickers_tw, tickers_us, start, end):
    data_dict = {}
    unique_tw = list(set(tickers_tw + ['0050']))
    unique_us = list(set(tickers_us + ['SPY']))
    
    for s in unique_tw:
        if not s: continue
        try:
            ticker = f"{s}.TW"
            yf_obj = yf.Ticker(ticker)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"å°è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")

    for s in unique_us:
        if not s: continue
        try:
            yf_obj = yf.Ticker(s)
            df = yf_obj.history(start=start, end=end, interval="1d", auto_adjust=True)
            if not df.empty:
                data_dict[s] = df['Close']
        except:
            st.sidebar.warning(f"ç¾è‚¡ {s} æŠ“å–å˜—è©¦å¤±æ•—")
    return data_dict

# --- 4. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header('ğŸ¯ æ¨™çš„è¨­å®š')
    tw_in = st.text_input('å°è‚¡ä»£è™Ÿ', '1215,1419,2430,2891,9918')
    us_in = st.text_input('ç¾è‚¡ä»£è™Ÿ', 'DBC,GLD,SPY,VCIT,VNQ,VTV,VUG')
    
    st.header('ğŸ“… æ™‚é–“èˆ‡è³‡é‡‘')
    start_date = st.date_input('é–‹å§‹æ—¥æœŸ', datetime.now() - timedelta(days=365*3))
    end_date = st.date_input('çµæŸæ—¥æœŸ', datetime.now())
    initial_cap = st.number_input('æœ¬é‡‘', value=100000)
    rf_rate = st.number_input('ç„¡é¢¨éšªåˆ©ç‡ (%)', value=4.0) / 100
    
    st.header('ğŸ² æ¨¡æ“¬è¨­å®š')
    num_simulations = st.slider('è’™åœ°å¡ç¾…æ¬¡æ•¸', 1000, 5000, 2000)
    forecast_len = st.slider('é æ¸¬å¤©æ•¸', 30, 365, 180)

# --- 5. ä¸»ç¨‹å¼åŸ·è¡Œ ---

# 1. åˆå§‹åŒ– Session State ç‹€æ…‹ï¼ˆé˜²æ­¢æ‹‰æ¡¿è§¸ç™¼é‡æ–°æ•´ç†å°è‡´ç•«é¢æ¶ˆå¤±ï¼‰
if 'analysis_started' not in st.session_state:
    st.session_state.analysis_started = False

# 2. é»æ“ŠæŒ‰éˆ•å¾Œï¼Œå°‡ç‹€æ…‹è¨­ç‚º True
if st.sidebar.button('ğŸš€ å•Ÿå‹•å…¨æ–¹ä½åˆ†æ', type="primary"):
    st.session_state.analysis_started = True

# 3. æ ¹æ“šç‹€æ…‹æ±ºå®šæ˜¯å¦é¡¯ç¤ºåˆ†æå…§å®¹
if st.session_state.analysis_started:
    tw_list = [x.strip() for x in tw_in.split(',') if x.strip()]
    us_list = [x.strip().upper() for x in us_in.split(',') if x.strip()]
    
    with st.spinner('æ­£åœ¨å¾ Yahoo Finance ç¯€é»æŠ“å–å…¨çƒè¤‡æ¬Šæ•¸æ“š...'):
        raw_data = fetch_stock_data(tw_list, us_list, start_date, end_date)
        
        if not raw_data:
            st.error("âŒ æ‰€æœ‰ä¾†æºå‡é€£ç·šå¤±æ•—ã€‚")
            st.stop()
            
        df_prices = pd.DataFrame(raw_data).ffill().dropna()
        returns = df_prices.pct_change().replace([np.inf, -np.inf], np.nan).dropna()

    st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df_prices.columns)} æª”è³‡ç”¢æ•¸æ“šï¼")
    st.download_button("ğŸ“¥ ä¸‹è¼‰èª¿æ•´å¾Œæ•¸æ“š (CSV)", df_prices.to_csv().encode('utf-8'), "data.csv")

    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["ğŸ“Š çµ±è¨ˆ", "ğŸ”— ç›¸é—œæ€§", "ğŸ’° æ¨¡æ“¬", "ğŸ“ å¸‚å ´æ¨¡å‹", "âš–ï¸ æ•ˆç‡å‰ç·£", "ğŸ”® é æ¸¬", "ğŸš¨ (é»‘å¤©éµ)å£“åŠ›æ¸¬è©¦"])

    with tab1:
        st.subheader("ğŸ“‹ çµ±è¨ˆç‰¹å¾µ")
        res_df = pd.DataFrame(index=returns.columns)
        total_days = (df_prices.index[-1] - df_prices.index[0]).days
        years = max(total_days / 365.25, 0.1) 
        
        res_df['å¹´åŒ–å ±é…¬'] = (df_prices.iloc[-1] / df_prices.iloc[0]) ** (1 / years) - 1
        res_df['å¹´åŒ–æ³¢å‹•'] = returns.std() * np.sqrt(252)
        res_df['å¤æ™®æ¯”ç‡'] = (res_df['å¹´åŒ–å ±é…¬'] - rf_rate) / res_df['å¹´åŒ–æ³¢å‹•']
        res_df['æœ€å¤§å›æ’¤'] = [calculate_mdd(df_prices[c])[0] for c in df_prices.columns]
        
        res_df['ç¬¦åˆå¸¸æ…‹'] = [("âœ… æ˜¯" if stats.jarque_bera(returns[c])[1] > 0.05 else "âŒ å¦") for c in returns.columns]
        
        numeric_cols = ['å¹´åŒ–å ±é…¬', 'å¹´åŒ–æ³¢å‹•', 'å¤æ™®æ¯”ç‡', 'æœ€å¤§å›æ’¤']
        st.dataframe(res_df.style.format({c: "{:.2%}" for c in numeric_cols}), use_container_width=True)
        
        cols = st.columns(2)
        for i, col in enumerate(returns.columns):
            with cols[i%2]:
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.hist(returns[col], bins=40, density=True, alpha=0.7, color='steelblue')
                ax.set_title(f"{col} Distribution of Returns")
                st.pyplot(fig)

    with tab2:
        st.subheader("ğŸ”— ç›¸é—œæ€§çŸ©é™£")
        fig, ax = plt.subplots(figsize=(10, 8))
        corr = returns.corr()
        im = ax.imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)
        plt.colorbar(im)
        ax.set_xticks(range(len(corr.columns))); ax.set_xticklabels(corr.columns, rotation=45)
        ax.set_yticks(range(len(corr.columns))); ax.set_yticklabels(corr.columns)
        st.pyplot(fig)

    with tab3:
        st.subheader("ğŸ’° è²¡å¯Œç´¯ç©æ›²ç·š")
        st.line_chart((1 + returns).cumprod() * initial_cap)

    with tab4:
        st.subheader("ğŸ“ å¸‚å ´æ¨¡å‹ (Beta)")
        beta_data = []
        for s in [c for c in returns.columns if c not in ['0050', 'SPY']]:
            if s.isdigit() and '0050' in returns.columns:
                mkt_ref = '0050'
            elif not s.isdigit() and 'SPY' in returns.columns:
                mkt_ref = 'SPY'
            else: continue
            common_df = pd.concat([returns[mkt_ref], returns[s]], axis=1).dropna()
            if len(common_df) > 10:
                slope, _, r_val, _, _ = stats.linregress(common_df.iloc[:,0], common_df.iloc[:,1])
                beta_data.append({"Asset": s, "Benchmark": mkt_ref, "Beta": slope, "R2": r_val**2})
        st.table(pd.DataFrame(beta_data))

# --- åœ¨ tab5 ä¹‹å‰å…ˆæº–å‚™å¥½æœ€ä½³åŒ–æ‰€éœ€çš„æ•¸æ“šèˆ‡å‡½æ•¸ ---
    import scipy.optimize as sco
    import matplotlib.ticker as mtick # å¼•å…¥ç™¾åˆ†æ¯”æ ¼å¼åŒ–å·¥å…·
 
    # 1. è¨ˆç®—æ—¥å‡å ±é…¬èˆ‡å…±è®Šç•°çŸ©é™£
    mu = returns.mean()
    S = returns.cov()
 
    def get_portfolio_performance(weights, mu, S, rf_rate):
        # è¨ˆç®—å¹´åŒ–å ±é…¬èˆ‡å¹´åŒ–æ³¢å‹•
        p_ret = np.sum(mu * weights) * 252
        p_std = np.sqrt(np.dot(weights.T, np.dot(S * 252, weights)))
        return p_ret, p_std
 
    def neg_sharpe_ratio(weights, mu, S, rf_rate):
        p_ret, p_std = get_portfolio_performance(weights, mu, S, rf_rate)
        return -(p_ret - rf_rate) / p_std
 
    def minimize_volatility(weights, mu, S, rf_rate):
        return get_portfolio_performance(weights, mu, S, rf_rate)[1]
 
    with tab5:
        st.subheader("âš–ï¸ æ•ˆç‡å‰ç·£èˆ‡æœ€ä½³é…ç½® (Scipy Optimize)")
    
    # --- 1. è¨ˆç®—é‚è¼¯ (å®Œå…¨ä¿ç•™æ‚¨çš„åŸå§‹é‚è¼¯) ---
        num_assets = len(returns.columns)
        sim_res = np.zeros((3, num_simulations))
        for i in range(num_simulations):
            w = np.random.random(num_assets)
            w /= np.sum(w)
            p_ret, p_std = get_portfolio_performance(w, mu, S, rf_rate)
            sim_res[0,i] = p_std
            sim_res[1,i] = p_ret
            sim_res[2,i] = (p_ret - rf_rate) / p_std 
 
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(num_assets))
        init_guess = num_assets * [1. / num_assets,]
 
        opt_sharpe = sco.minimize(neg_sharpe_ratio, init_guess, args=(mu, S, rf_rate), 
                                method='SLSQP', bounds=bounds, constraints=constraints)
        sharpe_ret, sharpe_vol = get_portfolio_performance(opt_sharpe.x, mu, S, rf_rate)
        best_weights = opt_sharpe.x 
 
        opt_vol = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                            method='SLSQP', bounds=bounds, constraints=constraints)
        min_vol_ret, min_vol_vol = get_portfolio_performance(opt_vol.x, mu, S, rf_rate)
 
        target_returns = np.linspace(min_vol_ret, max(sharpe_ret, sim_res[1].max()) * 1.05, 50)
        frontier_vol = []
        for t_ret in target_returns:
            cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                {'type': 'eq', 'fun': lambda x: get_portfolio_performance(x, mu, S, rf_rate)[0] - t_ret})
            res = sco.minimize(minimize_volatility, init_guess, args=(mu, S, rf_rate), 
                            method='SLSQP', bounds=bounds, constraints=cons)
            frontier_vol.append(res.fun if res.success else np.nan)
 
        # --- 2. ä¸Šæ–¹å€å¡Šï¼šæ•ˆç‡å‰ç·£å¤§åœ– (å–®ç¨ä¸€æ’) ---
        fig, ax = plt.subplots(figsize=(12, 6))
        sc = ax.scatter(sim_res[0,:], sim_res[1,:], c=sim_res[2,:], cmap='viridis', s=15, alpha=0.4, label='Random Portfolios')
        plt.colorbar(sc, label='Sharpe Ratio')
        ax.plot(frontier_vol, target_returns, 'b-', linewidth=2.5, label='Efficient Frontier')
    
        asset_ret = mu * 252
        asset_vol = np.sqrt(np.diag(S)) * np.sqrt(252)
        ax.scatter(asset_vol, asset_ret, marker='o', color='grey', s=50, label='Individual Assets')
        for i, txt in enumerate(returns.columns):
            ax.annotate(txt, (asset_vol[i], asset_ret[i]), xytext=(5,0), textcoords='offset points')
 
        ax.scatter(min_vol_vol, min_vol_ret, marker='*', color='orange', s=250, edgecolors='black', label='Min Volatility (MVP)', zorder=10)
        ax.scatter(sharpe_vol, sharpe_ret, marker='*', color='purple', s=250, edgecolors='black', label='Max Sharpe (MSR)', zorder=10)
    
        cml_x = np.linspace(0, max(sim_res[0].max(), sharpe_vol)*1.2, 100)
        cml_slope = (sharpe_ret - rf_rate) / sharpe_vol
        ax.plot(cml_x, rf_rate + cml_slope * cml_x, 'g--', label='Capital Market Line (CML)', alpha=0.7)
 
        ax.set_title(f"Efficient Frontier & Optimal Portfolios (Rf={rf_rate*100:.2f}%)", fontsize=14)
        ax.set_xlabel("Annualized Volatility (Risk)")
        ax.set_ylabel("Annualized Expected Return")
        ax.legend(loc='best')
        st.pyplot(fig)
 
        st.markdown("---")
 
    # --- 3. ä¸‹æ–¹å€å¡Šï¼šå…©å€‹åœ“é¤…åœ–ä¸¦æ’ ---
        col_left, col_right = st.columns(2)
 
        with col_left:
            st.write("#### ğŸ† Maximum Sharpe Ratio (MSR)")
            df_sharpe = pd.DataFrame({'Asset': returns.columns, 'Weight': best_weights * 100})
            df_sharpe = df_sharpe.sort_values(by='Weight', ascending=False)
            fig_pie1, ax_pie1 = plt.subplots(figsize=(4, 4))
            ax_pie1.pie(df_sharpe['Weight'], labels=df_sharpe['Asset'], autopct='%1.1f%%', startangle=90)
            st.pyplot(fig_pie1)
            st.dataframe(df_sharpe.style.format({'Weight': '{:.2f}%'}), hide_index=True, use_container_width=True)
            st.info(f"Ret: {sharpe_ret:.2%} / Vol: {sharpe_vol:.2%}")
 
        with col_right:
            st.write("#### ğŸ›¡ï¸ Minimum Variance Portfolio (MVP)")
            df_mvp = pd.DataFrame({'Asset': returns.columns, 'Weight': opt_vol.x * 100})
            df_mvp = df_mvp.sort_values(by='Weight', ascending=False)
            fig_pie2, ax_pie2 = plt.subplots(figsize=(4, 4))
            ax_pie2.pie(df_mvp['Weight'], labels=df_mvp['Asset'], autopct='%1.1f%%', startangle=90)
            st.pyplot(fig_pie2)
            st.dataframe(df_mvp.style.format({'Weight': '{:.2f}%'}), hide_index=True, use_container_width=True)
            st.info(f"Ret: {min_vol_ret:.2%} / Vol: {min_vol_vol:.2%}")            


# --- TAB 6: å®Œå…¨ä¿®å¾©ç‰ˆ (æ¢å¾©å®Œæ•´çµ±è¨ˆæŒ‡æ¨™ + åƒæ•¸çœ‹æ¿ + é›™é‡åˆ†æ) ---
    with tab6:
        st.markdown("#### ğŸ”® è’™åœ°å¡ç¾…é æ¸¬ï¼šå¹¾ä½•å¸ƒæœ—é‹å‹•æ¨¡å‹ (GBM Simulation)")

        # 1. åƒæ•¸è¨­å®š
        n_sim_total = 1000  # æ¨¡æ“¬æ¬¡æ•¸
        n_plot = 50         # ç¹ªåœ–è·¯å¾‘æ•¸
        
        # 2. æ ¸å¿ƒåƒæ•¸æº–å‚™ (MSR)
        port_returns_series = (returns * best_weights).sum(axis=1)
        
        # è¨ˆç®—çœŸæ­£çš„å¹´åŒ–åƒæ•¸ (é¡¯ç¤ºæ–¼çœ‹æ¿)
        mu_p = port_returns_series.mean() * 252
        sigma_p = port_returns_series.std() * np.sqrt(252)
        
        s0 = initial_cap
        dt = 1/252
        
        # --- åƒæ•¸çœ‹æ¿ (é¡¯ç¤ºçœŸæ­£çš„æ¨¡å‹è¼¸å…¥å€¼) ---
        st.markdown(f"""
        <div style="background-color: #e8f4f8; padding: 15px; border-radius: 8px; border-left: 5px solid #0984e3; margin-bottom: 20px;">
            <h5 style="margin:0; color: #2d3436;">âš™ï¸ æ¨¡å‹è¼¸å…¥åƒæ•¸ (Model Input Parameters)</h5>
            <p style="margin:5px 0 0 0; color: #636e72; font-size: 14px;">
                æ­¤æ¨¡æ“¬åŸºæ–¼ <b>æœ€å¤§å¤æ™®æ¯”ç‡çµ„åˆ (MSR)</b> ä¹‹æ­·å²çµ±è¨ˆç‰¹å¾µï¼š<br>
                â€¢ <b>å¹´åŒ–é æœŸå ±é…¬ç‡ ($\mu$)</b> : <span style="color: #d63031; font-weight: bold;">{mu_p:.2%}</span><br>
                â€¢ <b>å¹´åŒ–æ³¢å‹•ç‡ ($\sigma$)</b> : <span style="color: #d63031; font-weight: bold;">{sigma_p:.2%}</span>
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # 3. åŸ·è¡Œ GBM æ¨¡æ“¬
        sim_paths = np.zeros((forecast_len, n_sim_total))
        sim_paths[0] = s0
        
        drift = (mu_p - 0.5 * sigma_p**2) * dt
        shock = sigma_p * np.sqrt(dt)
        
        z_matrix = np.random.normal(0, 1, (forecast_len - 1, n_sim_total))
        
        for t in range(1, forecast_len):
            sim_paths[t] = sim_paths[t-1] * np.exp(drift + shock * z_matrix[t-1])
            
        # 4. è·¯å¾‘æ¨¡æ“¬åœ–
        st.write(f"**ğŸ“ˆ è³‡ç”¢åƒ¹æ ¼è·¯å¾‘æ¨¡æ“¬ (Asset Price Paths)**")
        st.line_chart(sim_paths[:, :n_plot])

        # 5. æ•¸æ“šå‰è™•ç†
        final_values = sim_paths[-1, :]
        daily_diff = np.diff(sim_paths, axis=0)
        up_counts = np.sum(daily_diff > 0, axis=0)

        # ==========================================
        # Part A: é€£çºŒè®Šæ•¸åˆ†æ (Terminal Wealth)
        # ==========================================
        st.markdown("### 1 é€£çºŒè®Šæ•¸åˆ†æï¼šæœŸæœ«è²¡å¯Œåˆ†ä½ˆ (Terminal Wealth)")
        
        # --- é€™è£¡æ¢å¾©æ‚¨åŸæœ¬å®Œæ•´çš„çµ±è¨ˆè¨ˆç®— ---
        # 1. åŸºç¤çµ±è¨ˆ
        mean_end = np.mean(final_values)
        median_end = np.median(final_values)
        
        # 2. ç²åˆ©èƒ½åŠ›æŒ‡æ¨™
        max_profit = np.max(final_values) - s0 # æœ€å¤§ç²åˆ©
        prob_profit = np.sum(final_values > s0) / n_sim_total # å‹ç‡
        
        # 3. é¢¨éšªæŒ‡æ¨™ (å¾æ¨¡æ“¬çµæœåæ¨)
        log_returns = np.log(final_values / s0)
        realized_vol = np.std(log_returns) / np.sqrt(forecast_len / 252) # å¯¦ç¾æ³¢å‹•ç‡
        
        # 4. é¢¨éšªæº¢é…¬
        rf_end_value = s0 * np.exp(rf_rate * (forecast_len / 252))
        risk_premium = mean_end - rf_end_value
        
        # 5. ä¸‹æª”é¢¨éšª
        var_95 = np.percentile(final_values, 5)
        cvar_95 = final_values[final_values <= var_95].mean()
        
        # --- é¡¯ç¤ºå®Œæ•´çš„çµ±è¨ˆçœ‹æ¿ (3æ¬„ä½) ---
        col_c1, col_c2, col_c3 = st.columns(3)
        
        with col_c1: 
            st.metric("å¹³å‡æœŸæœ«è³‡ç”¢", f"${mean_end:,.0f}", delta=f"{(mean_end/s0 -1):.2%}")
            st.metric("ä¸­ä½æ•¸è³‡ç”¢", f"${median_end:,.0f}")
            st.metric("æ¨¡æ“¬å¹´åŒ–æ³¢å‹•ç‡", f"{realized_vol:.2%}", help="å¾æ¨¡æ“¬è·¯å¾‘åæ¨çš„å¯¦éš›æ³¢å‹•ç¨‹åº¦")

        with col_c2: 
            st.metric("æ­£å ±é…¬æ©Ÿç‡ (Win Rate)", f"{prob_profit:.1%}")
            st.metric("é æœŸæœ€å¤§ç²åˆ© (Net)", f"${max_profit:,.0f}")
            st.metric("é æœŸé¢¨éšªæº¢é…¬", f"${risk_premium:,.0f}", help=f"å¹³å‡çµ‚å€¼ - ç„¡é¢¨éšªåˆ©ç‡çµ‚å€¼ (${rf_end_value:,.0f})")
            
        with col_c3: 
            st.markdown("#### âš ï¸ ä¸‹æª”é¢¨éšª (Tail Risk)")
            st.metric("é¢¨éšªå€¼ VaR (95%)", f"${var_95:,.0f}", delta=f"{(var_95/s0 -1):.2%}", delta_color="inverse")
            st.caption(f"æ¢ä»¶é¢¨éšªå€¼ CVaR (æœ€å·®5%å¹³å‡): ${cvar_95:,.0f}")

        # æ“¬åˆåˆ†æ
        dist_candidates_cont = {
            "Log-Normal": stats.lognorm,
            "Gamma": stats.gamma,
            "Student's t": stats.t,
            "Chi-Squared": stats.chi2,
            "Beta": stats.beta
        }
        
        fit_results_cont = []
        for name, dist in dist_candidates_cont.items():
            try:
                params = dist.fit(final_values)
                D, p = stats.kstest(final_values, dist.cdf, args=params)
                fit_results_cont.append({"Model": name, "D_Statistic": D, "params": params, "dist": dist})
            except: pass
        
        fit_results_cont.sort(key=lambda x: x['D_Statistic'])
        best_fit_cont = fit_results_cont[0]

        # ç¹ªåœ– A (è‹±æ–‡åœ–è¡¨)
        col_plot_c, col_rank_c = st.columns([3, 1])
        with col_plot_c:
            fig_cont, ax_cont = plt.subplots(figsize=(10, 5))
            ax_cont.hist(final_values, bins=60, density=True, alpha=0.5, color='#3498db', label='Simulated Data', edgecolor='white')
            x_fit = np.linspace(np.min(final_values), np.max(final_values), 200)
            pdf_fit = best_fit_cont['dist'].pdf(x_fit, *best_fit_cont['params'])
            ax_cont.plot(x_fit, pdf_fit, 'r-', lw=2.5, label=f"Best Fit: {best_fit_cont['Model']}")
            
            # English Labels
            ax_cont.set_title(f"Continuous Fit: Terminal Wealth (Best: {best_fit_cont['Model']})", fontsize=12)
            ax_cont.set_xlabel("Portfolio Value ($)", fontsize=10)
            ax_cont.set_ylabel("Probability Density", fontsize=10)
            ax_cont.legend(loc='upper right')
            import matplotlib.ticker as mticker
            ax_cont.xaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))
            st.pyplot(fig_cont)
            
        with col_rank_c:
            st.markdown("**æ“¬åˆå„ªåº¦ (Goodness of Fit)**")
            st.dataframe(pd.DataFrame(fit_results_cont)[['Model', 'D_Statistic']], hide_index=True)

        # Aéƒ¨åˆ†ï¼šçµ±è¨ˆè§£é‡‹
        winner_model_c = best_fit_cont['Model']
        explanation_c = ""
        if "Log-Normal" in winner_model_c:
            explanation_c = "ç¬¦åˆ **å¹¾ä½•å¸ƒæœ—é‹å‹• (GBM)** çš„ç†è«–é æœŸã€‚è³‡ç”¢åƒ¹æ ¼å› å…·æœ‰è¤‡åˆ©æ•ˆæ‡‰ä¸”æ†ç‚ºæ­£å€¼ï¼Œæ•…å‘ˆç¾å³åçš„å°æ•¸å¸¸æ…‹åˆ†ä½ˆã€‚"
        elif "Student's t" in winner_model_c:
            explanation_c = "åˆ†ä½ˆå…·æœ‰**åšå°¾ (Fat Tails)** ç‰¹å¾µã€‚é€™æ„å‘³è‘—å¸‚å ´å‡ºç¾æ¥µç«¯é»‘å¤©éµäº‹ä»¶çš„æ©Ÿç‡ï¼Œæ¯”æ¨™æº–å¸¸æ…‹åˆ†ä½ˆé æ¸¬çš„é‚„è¦é«˜ã€‚"
        else:
            explanation_c = "æ•¸æ“šåˆ†ä½ˆå‘ˆç¾ç‰¹å®šçµ±è¨ˆç‰¹å¾µï¼Œå¯èƒ½å—çŸ­æœŸæ³¢å‹•æˆ–åƒæ•¸è¨­å®šå½±éŸ¿ã€‚"

        st.info(f"ğŸ’¡ **çµ±è¨ˆçµè«–**ï¼š\næœ€ä½³æ“¬åˆæ¨¡å‹ç‚º **{winner_model_c}**ã€‚\n\n**ğŸ“ å°ˆæ¥­è§£è®€**ï¼š{explanation_c}")

        st.markdown("---")

        # ==========================================
        # Part B: é›¢æ•£è®Šæ•¸åˆ†æ (Up Days Frequency)
        # ==========================================
        st.markdown("### 2 é›¢æ•£è®Šæ•¸åˆ†æï¼šæ­£å ±é…¬é »ç‡åˆ†ä½ˆ (Positive Return Frequency)")
        
        st.markdown("""
        <div style="background-color: #f8f9fa; padding: 12px; border-radius: 5px; font-size: 13px; color: #333; border: 1px solid #ddd;">
            <b>ğŸ“Š çµ±è¨ˆç†è«–åŸºç¤ (Theoretical Basis)ï¼š</b><br>
            åŸºæ–¼ <b>éš¨æ©Ÿæ¼«æ­¥å‡èªª (Random Walk Hypothesis)</b>ï¼Œè³‡ç”¢æ¯æ—¥åƒ¹æ ¼è®Šå‹•å¯è¿‘ä¼¼ç‚ºä¸€ç³»åˆ—ç¨ç«‹çš„ <b>ä¼¯åŠªåˆ©è©¦é©— (Bernoulli Trials)</b>ã€‚<br>
            æœ¬ç¯€åˆ†æé æ¸¬æœŸé–“å…§ï¼Œè³‡ç”¢å‘ˆç¾<b>æ­£å ±é…¬ (Positive Return)</b> äº¤æ˜“æ—¥ä¹‹è¨ˆæ•¸åˆ†ä½ˆã€‚<br>
            ç†è«–ä¸Šï¼Œè‹¥å¸‚å ´ç‚ºéš¨æ©Ÿæ¼«æ­¥ï¼Œå…¶åˆ†ä½ˆæ‡‰æ”¶æ–‚æ–¼ <b>äºŒé …åˆ†ä½ˆ (Binomial Distribution)</b>ã€‚
        </div>
        """, unsafe_allow_html=True)

        # çµ±è¨ˆæŒ‡æ¨™
        mean_up = np.mean(up_counts)
        prob_up = mean_up / forecast_len
        std_up = np.std(up_counts)
        
        col_d1, col_d2, col_d3 = st.columns(3)
        with col_d1: st.metric("æœŸæœ›æ­£å ±é…¬å¤©æ•¸", f"{mean_up:.1f} Days")
        with col_d2: st.metric("å–®æ—¥æ­£å ±é…¬æ©Ÿç‡ $p$", f"{prob_up:.2%}")
        with col_d3: st.metric("é »ç‡æ¨™æº–å·®", f"{std_up:.2f}")

        # æ“¬åˆåˆ†æ
        x_min, x_max = np.min(up_counts), np.max(up_counts)
        x_discrete = np.arange(x_min, x_max + 1)
        observed_counts = np.bincount(up_counts.astype(int))
        if len(observed_counts) > x_max:
            observed_pmf = observed_counts[x_min : x_max+1] / n_sim_total
        else:
            observed_pmf = np.zeros(len(x_discrete))
            
        discrete_candidates = []
        
        # (A) Binomial
        binom_pmf = stats.binom.pmf(x_discrete, n=forecast_len, p=prob_up)
        rmse_binom = np.sqrt(np.mean((observed_pmf - binom_pmf)**2))
        discrete_candidates.append({"Model": "Binomial Dist.", "RMSE": rmse_binom, "pmf": binom_pmf})

        # (B) Poisson
        poisson_pmf = stats.poisson.pmf(x_discrete, mu=mean_up)
        rmse_poisson = np.sqrt(np.mean((observed_pmf - poisson_pmf)**2))
        discrete_candidates.append({"Model": "Poisson Dist.", "RMSE": rmse_poisson, "pmf": poisson_pmf})

        # (C) Normal Approx
        norm_approx_pdf = stats.norm.pdf(x_discrete, loc=mean_up, scale=std_up)
        norm_approx_pmf = norm_approx_pdf / np.sum(norm_approx_pdf)
        rmse_norm = np.sqrt(np.mean((observed_pmf - norm_approx_pmf)**2))
        discrete_candidates.append({"Model": "Normal Approx.", "RMSE": rmse_norm, "pmf": norm_approx_pmf})

        discrete_candidates.sort(key=lambda x: x['RMSE'])
        best_discrete = discrete_candidates[0]

        # ç¹ªåœ– B (è‹±æ–‡åœ–è¡¨)
        col_plot_d, col_rank_d = st.columns([3, 1])
        with col_plot_d:
            fig_disc, ax_disc = plt.subplots(figsize=(10, 5))
            # Bar
            ax_disc.bar(x_discrete, observed_pmf, alpha=0.6, color='#f39c12', label='Observed Frequency', zorder=1)
            # Line (Best)
            ax_disc.plot(x_discrete, best_discrete['pmf'], 'b-o', ms=5, lw=2.5, label=f"Best Fit: {best_discrete['Model']}", zorder=2)
            # Binomial Reference
            if "Binomial" not in best_discrete['Model']:
                binom_res = next(item for item in discrete_candidates if "Binomial" in item["Model"])
                ax_disc.plot(x_discrete, binom_res['pmf'], 'k--', alpha=0.5, lw=1.5, label='Theoretical: Binomial', zorder=2)

            # English Labels
            ax_disc.set_title(f"Discrete Fit: Frequency of Positive Returns (Winner: {best_discrete['Model']})", fontsize=12)
            ax_disc.set_xlabel("Number of Positive Days", fontsize=10)
            ax_disc.set_ylabel("Probability Mass", fontsize=10)
            ax_disc.legend(loc='upper left')
            st.pyplot(fig_disc)
            
        with col_rank_d:
            st.markdown("**æ¨¡å‹æ“¬åˆæ’å**")
            st.caption("å‡æ–¹æ ¹èª¤å·® RMSE (è¶Šä½è¶Šä½³)")
            for res in discrete_candidates:
                st.markdown(f"**{res['Model']}**")
                st.caption(f"RMSE: {res['RMSE']:.4f}")
        
        # Béƒ¨åˆ†ï¼šçµ±è¨ˆè§£é‡‹
        winner_model_d = best_discrete['Model']
        explanation_d = ""
        if "Binomial" in winner_model_d:
            explanation_d = "å®Œå…¨ç¬¦åˆ **éš¨æ©Ÿæ¼«æ­¥å‡èªª (Random Walk)**ã€‚é€™è­‰å¯¦äº†æ¯æ—¥çš„åƒ¹æ ¼æ¼²è·Œå¯è¢«è¦–ç‚ºç¨ç«‹çš„äº‹ä»¶ï¼Œä¸”ç¬¦åˆç†è«–ä¸Šçš„äºŒé …åˆ†ä½ˆç‰¹å¾µã€‚"
        elif "Normal Approx" in winner_model_d:
            explanation_d = "é«”ç¾ **ä¸­å¤®æ¥µé™å®šç† (Central Limit Theorem)**ã€‚ç•¶é æ¸¬å¤©æ•¸ (N) è¶³å¤ å¤§æ™‚ï¼ŒäºŒé …åˆ†ä½ˆæœƒè‡ªç„¶æ”¶æ–‚è‡³å¸¸æ…‹åˆ†ä½ˆï¼Œé€™æ˜¯å¤§æ¨£æœ¬ä¸‹çš„æ­£å¸¸çµ±è¨ˆç¾è±¡ã€‚"
        else:
            explanation_d = "æ¨¡æ“¬çµæœé¡¯ç¤ºå‡ºç‰¹æ®Šçš„è¨ˆæ•¸åˆ†ä½ˆç‰¹å¾µã€‚"

        st.info(f"ğŸ’¡ **çµ±è¨ˆçµè«–**ï¼š\næœ€ä½³æ“¬åˆæ¨¡å‹ç‚º **{winner_model_d}**ã€‚\n\n**ğŸ“ å°ˆæ¥­è§£è®€**ï¼š{explanation_d}")

        # --- TAB 7: å£“åŠ›æ¸¬è©¦ ---
        with tab7:
            st.subheader("ğŸš¨ æŠ•è³‡çµ„åˆå£“åŠ›æ¸¬è©¦ (Stress Test)")
            
            # 1. è¨ˆç®—çµ„åˆçš„åŠ æ¬Š Beta (åæ˜ çµ„åˆå°å¸‚å ´çš„æ•æ„Ÿåº¦)
            # é€™è£¡å¾ä½  TAB 4 çš„ beta_data æå–è³‡æ–™
            if len(beta_data) > 0:
                df_beta = pd.DataFrame(beta_data)
                # å»ºç«‹æ¬Šé‡å­—å…¸æ–¹ä¾¿æŸ¥è©¢
                weight_dict = dict(zip(returns.columns, best_weights))
                # è¨ˆç®—çµ„åˆ Beta = Î£ (æ¬Šé‡ * å€‹è‚¡ Beta)
                df_beta['Weighted Beta'] = df_beta.apply(lambda x: x['Beta'] * weight_dict.get(x['Asset'], 0), axis=1)
                port_beta = df_beta['Weighted Beta'].sum()
            else:
                port_beta = 1.0 # é è¨­å€¼
                
            col1, col2 = st.columns([2, 3])
            
            with col1:
                st.write("**è‡ªå®šç¾©å¸‚å ´è¡æ“Šé æ¸¬**")
                mkt_shock = st.slider("å‡è¨­å¤§ç›¤(å¸‚å ´åŸºæº–)ä¸‹è·Œ (%)", -50, 0, -10)
                
                # é ä¼°æå¤± = æœ¬é‡‘ * å¸‚å ´è·Œå¹… * çµ„åˆ Beta
                est_loss_pct = (mkt_shock / 100) * port_beta
                est_loss_amt = initial_cap * est_loss_pct
                
                st.metric("é ä¼°çµ„åˆè·Œå¹…", f"{est_loss_pct:.2%}", delta=f"{est_loss_pct:.2%}")
                st.metric("é ä¼°æå¤±é‡‘é¡", f"${est_loss_amt:,.0f}")
                
            with col2:
                st.write("**æ­·å²æ¥µç«¯æƒ…å¢ƒæ¨¡æ“¬**")
                scenarios = {
                    "2008 é‡‘èæµ·å˜¯ (å‡è¨­å¤§ç›¤ -20%)": -0.20,
                    "2020 ç–«æƒ…å´©ç›¤ (å‡è¨­å¤§ç›¤ -15%)": -0.15,
                    "2022 å‡æ¯ç¸®è¡¨ (å‡è¨­å¤§ç›¤ -10%)": -0.10,
                    "å¾®å¹…ä¿®æ­£ (å‡è¨­å¤§ç›¤ -5%)": -0.05
                }
                
                scene_data = []
                for name, shock in scenarios.items():
                    loss_pct = shock * port_beta
                    scene_data.append({
                        "æƒ…å¢ƒ": name,
                        "å¤§ç›¤è·Œå¹…": f"{shock:.0%}",
                        "çµ„åˆé ä¼°è·Œå¹…": f"{loss_pct:.2%}",
                        "é ä¼°æå¤±é‡‘é¡": f"${initial_cap * loss_pct:,.0f}"
                    })
                
                st.table(pd.DataFrame(scene_data))
    
            st.info(f"ğŸ’¡ è¨»ï¼šç›®å‰çµ„åˆçš„åŠ æ¬Š Beta ç‚º **{port_beta:.2f}**ã€‚é€™ä»£è¡¨ç•¶å¤§ç›¤ä¸‹è·Œ 1% æ™‚ï¼Œé è¨ˆä½ çš„çµ„åˆæœƒéš¨ä¹‹è®Šå‹• {abs(port_beta):.2f}%ã€‚")
